{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import essentia.standard as ess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed' / 'birdcall_segments_5s_113'\n",
    "METADATA_PATH = DATA_DIR / 'processed' / 'birdcall_metadata_113.csv'\n",
    "FEATURES_DIR = DATA_DIR / 'features'\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_metadata():\n",
    "    \"\"\"Load and validate metadata CSV\"\"\"\n",
    "    metadata = pd.read_csv(METADATA_PATH)\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = {'filename', 'species', 'call_type'}\n",
    "    if not required_cols.issubset(metadata.columns):\n",
    "        missing = required_cols - set(metadata.columns)\n",
    "        raise ValueError(f\"Metadata missing required columns: {missing}\")\n",
    "    \n",
    "    # Create full paths and verify files exist\n",
    "    metadata['full_path'] = metadata['filename'].apply(\n",
    "        lambda x: str(PROCESSED_DATA_DIR / x)\n",
    "    )\n",
    "    \n",
    "    # Check which files actually exist\n",
    "    metadata['file_exists'] = metadata['full_path'].apply(\n",
    "        lambda x: Path(x).exists()\n",
    "    )\n",
    "    \n",
    "    existing_files = metadata[metadata['file_exists']]\n",
    "    if len(existing_files) == 0:\n",
    "        raise FileNotFoundError(\"No audio files found matching metadata records\")\n",
    "    \n",
    "    print(f\"Loaded metadata for {len(metadata)} records\")\n",
    "    print(f\"Found {len(existing_files)} matching audio files\")\n",
    "    \n",
    "    return existing_files[['full_path', 'species', 'call_type']].to_dict('records')\n",
    "\n",
    "def initialize_extractor():\n",
    "    \"\"\"Configure audio feature extractor with optimal settings\"\"\"\n",
    "    return ess.FreesoundExtractor(\n",
    "        lowlevelStats=[\"mean\", \"stdev\"],\n",
    "        tonalStats=[\"mean\", \"stdev\"],\n",
    "        mfccStats=[\"mean\", \"stdev\"],\n",
    "        gfccStats=[\"mean\", \"stdev\"],\n",
    "        lowlevelFrameSize=2048,  # Smaller window for bird calls\n",
    "        lowlevelHopSize=1024,\n",
    "        lowlevelSilentFrames=\"drop\"\n",
    "    )\n",
    "\n",
    "def extract_features(audio_files, output_csv):\n",
    "    \"\"\"Batch feature extraction with progress tracking\"\"\"\n",
    "    extractor = initialize_extractor()\n",
    "    features_data = []\n",
    "    failed_files = []\n",
    "    \n",
    "    # Get feature names from first successful file\n",
    "    sample_features = None\n",
    "    for file in audio_files[:5]:  # Try first 5 files\n",
    "        try:\n",
    "            features, _ = extractor(file['full_path'])\n",
    "            sample_features = features\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    if sample_features is None:\n",
    "        raise RuntimeError(\"Could not extract features from any sample file\")\n",
    "    \n",
    "    # Select only numeric features (skip arrays)\n",
    "    feature_names = sorted([\n",
    "        desc for desc in sample_features.descriptorNames()\n",
    "        if isinstance(sample_features[desc], (float, int)) and \n",
    "        any(x in desc for x in [\"lowlevel\", \"mfcc\", \"gfcc\", \"tonal\"])\n",
    "    ])\n",
    "    \n",
    "    # Batch processing with error handling\n",
    "    for file in tqdm(audio_files, desc=\"Extracting features\"):\n",
    "        try:\n",
    "            features, _ = extractor(file['full_path'])\n",
    "            row = {name: features[name] for name in feature_names}\n",
    "            row.update({\n",
    "                'species': file['species'],\n",
    "                'call_type': file['call_type'],\n",
    "                'filename': Path(file['full_path']).name\n",
    "            })\n",
    "            features_data.append(row)\n",
    "        except Exception as e:\n",
    "            failed_files.append((file['full_path'], str(e)))\n",
    "    \n",
    "    # Error reporting\n",
    "    if failed_files:\n",
    "        print(f\"\\nFailed to process {len(failed_files)} files ({(len(failed_files)/len(audio_files)*100):.1f}%)\")\n",
    "        for path, error in failed_files[:3]:\n",
    "            print(f\"- {Path(path).name}: {error}\")\n",
    "    \n",
    "    # Create and save dataframe\n",
    "    features_df = pd.DataFrame(features_data)\n",
    "    \n",
    "    # Versioned output\n",
    "    version = 1\n",
    "    while output_csv.exists():\n",
    "        output_csv = output_csv.parent / f\"{output_csv.stem}_v{version}{output_csv.suffix}\"\n",
    "        version += 1\n",
    "    \n",
    "    features_df.to_csv(output_csv, index=False)\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"üöÄ Starting Bird Call Feature Extraction Pipeline\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Load and validate data\n",
    "        print(\"\\nüîç Loading metadata and audio files...\")\n",
    "        audio_files = load_metadata()\n",
    "        \n",
    "        # 2. Feature extraction\n",
    "        print(\"\\n‚öôÔ∏è Extracting audio features...\")\n",
    "        features_csv = FEATURES_DIR / 'birdcall_features_113.csv'\n",
    "        features_df = extract_features(audio_files, features_csv)\n",
    "        print(f\"‚úÖ Extracted {len(features_df.columns)-3} features from {len(features_df)} files\")\n",
    "        \n",
    "        print(f\"\\nüéâ Pipeline completed! Features saved to:\\n{features_csv}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Pipeline failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP 50 BIRD SELECTION (THE USER COULD SELECT THE SUBSET THEY WANT TO TRAIN WITH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "# Original folders and files\n",
    "ORIGINAL_SEGMENTS_DIR = PROCESSED_DATA_DIR / 'birdcall_segments_5s_113'\n",
    "ORIGINAL_METADATA = PROCESSED_DATA_DIR / 'birdcall_metadata_113.csv'\n",
    "\n",
    "# New folders for top 50\n",
    "TOP50_SEGMENTS_DIR = PROCESSED_DATA_DIR / 'birdcall_segments_5s_TOP50'\n",
    "TOP50_METADATA = PROCESSED_DATA_DIR / 'birdcall_metadata_TOP50.csv'\n",
    "\n",
    "# List of top 50 bird species (from your ranking) with both naming formats\n",
    "TOP50_SPECIES = {\n",
    "    # Format: \"Display Name\": [\"csv_name\", \"filename_prefix\"]\n",
    "    \"Curve-billed Tinamou\": [\"curve-billed_tinamou\", \"curve-billed_tinamou\"],\n",
    "    \"Tongan Megapode\": [\"tongan_megapode\", \"tongan_megapode\"],\n",
    "    \"Micronesian Megapode\": [\"micronesian_megapode\", \"micronesian_megapode\"],\n",
    "    \"Elegant Crested Tinamou\": [\"elegant_crested_tinamou\", \"elegant_crested_tinamou\"],\n",
    "    \"Tepui Tinamou\": [\"tepui_tinamou\", \"tepui_tinamou\"],\n",
    "    \"Cinereous Tinamou\": [\"cinereous_tinamou\", \"cinereous_tinamou\"],\n",
    "    \"Lesser Nothura\": [\"lesser_nothura\", \"lesser_nothura\"],\n",
    "    \"Puna Tinamou\": [\"puna_tinamou\", \"puna_tinamou\"],\n",
    "    \"Lesser Rhea\": [\"lesser_rhea\", \"lesser_rhea\"],\n",
    "    \"Barred Tinamou\": [\"barred_tinamou\", \"barred_tinamou\"],\n",
    "    \"Dwarf Tinamou\": [\"dwarf_tinamou\", \"dwarf_tinamou\"],\n",
    "    \"Little Spotted Kiwi\": [\"little_spotted_kiwi\", \"little_spotted_kiwi\"],\n",
    "    \"Sula Megapode\": [\"sula_megapode\", \"sula_megapode\"],\n",
    "    \"Vanuatu Megapode\": [\"vanuatu_megapode\", \"vanuatu_megapode\"],\n",
    "    \"Baudo Guan\": [\"baudo_guan\", \"baudo_guan\"],\n",
    "    \"Undulated Tinamou\": [\"undulated_tinamou\", \"undulated_tinamou\"],\n",
    "    \"Biak Scrubfowl\": [\"biak_scrubfowl\", \"biak_scrubfowl\"],\n",
    "    \"Bartlett's Tinamou\": [\"bartlett's_tinamou\", \"bartletts'_tinamou\"],\n",
    "    \"Huayco Tinamou\": [\"huayco_tinamou\", \"huayco_tinamou\"],\n",
    "    \"Wattled Brushturkey\": [\"wattled_brushturkey\", \"wattled_brushturkey\"],\n",
    "    \"Chestnut-headed Chachalaca\": [\"chestnut-headed_chachalaca\", \"chestnut-headed_chachalaca\"],\n",
    "    \"Common Ostrich\": [\"common_ostrich\", \"common_ostrich\"],\n",
    "    \"New Guinea Scrubfowl\": [\"new_guinea_scrubfowl\", \"new_guinea_scrubfowl\"],\n",
    "    \"Ornate Tinamou\": [\"ornate_tinamou\", \"ornate_tinamou\"],\n",
    "    \"Trinidad Piping Guan\": [\"trinidad_piping_guan\", \"trinidad_piping_guan\"],\n",
    "    \"Red-billed Brushturkey\": [\"red-billed_brushturkey\", \"red-billed_brushturkey\"],\n",
    "    \"Andean Guan\": [\"andean_guan\", \"andean_guan\"],\n",
    "    \"Quebracho Crested Tinamou\": [\"quebracho_crested_tinamou\", \"quebracho_crested_tinamou\"],\n",
    "    \"Berlepsch's Tinamou\": [\"berlepsch's_tinamou\", \"berlepsch's_tinamou\"],\n",
    "    \"White-winged Guan\": [\"white-winged_guan\", \"white-winged_guan\"],\n",
    "    \"Hooded Tinamou\": [\"hooded_tinamou\", \"hooded_tinamou\"],\n",
    "    \"Southern Brown Kiwi\": [\"southern_brown_kiwi\", \"southern_brown_kiwi\"],\n",
    "    \"Great Spotted Kiwi\": [\"great_spotted_kiwi\", \"great_spotted_kiwi\"],\n",
    "    \"Chilean Tinamou\": [\"chilean_tinamou\", \"chilean_tinamou\"],\n",
    "    \"Band-tailed Guan\": [\"band-tailed_guan\", \"band-tailed_guan\"],\n",
    "    \"Highland Tinamou\": [\"highland_tinamou\", \"highland_tinamou\"],\n",
    "    \"Malleefowl\": [\"malleefowl\", \"malleefowl\"],\n",
    "    \"Bearded Guan\": [\"bearded_guan\", \"bearded_guan\"],\n",
    "    \"Brown Tinamou\": [\"brown_tinamou\", \"brown_tinamou\"],\n",
    "    \"White-bellied Nothura\": [\"white-bellied_nothura\", \"white-bellied_nothura\"],\n",
    "    \"Spix's Guan\": [\"spix's_guan\", \"spix's_guan\"],\n",
    "    \"Choco Tinamou\": [\"choco_tinamou\", \"choco_tinamou\"],\n",
    "    \"Grey-headed Chachalaca\": [\"grey-headed_chachalaca\", \"grey-headed_chachalaca\"],\n",
    "    \"Black-fronted Piping Guan\": [\"black-fronted_piping_guan\", \"black-fronted_piping_guan\"],\n",
    "    \"Cauca Guan\": [\"cauca_guan\", \"cauca_guan\"],\n",
    "    \"Thicket Tinamou\": [\"thicket_tinamou\", \"thicket_tinamou\"],\n",
    "    \"Great Tinamou\": [\"great_tinamou\", \"great_tinamou\"],\n",
    "    \"Dusky-legged Guan\": [\"dusky-legged_guan\", \"dusky-legged_guan\"],\n",
    "    \"Chaco Chachalaca\": [\"chaco_chachalaca\", \"chaco_chachalaca\"],\n",
    "    \"Black-capped Tinamou\": [\"black-capped_tinamou\", \"black-capped_tinamou\"]\n",
    "}\n",
    "\n",
    "def create_top50_dataset():\n",
    "    # Create output directory if it doesn't exist\n",
    "    TOP50_SEGMENTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load original metadata\n",
    "    original_metadata_df = pd.read_csv(ORIGINAL_METADATA)\n",
    "    \n",
    "    # Create a mapping from CSV species names to display names\n",
    "    species_mapping = {v[0]: k for k, v in TOP50_SPECIES.items()}\n",
    "    \n",
    "    # Filter metadata for top 50 species\n",
    "    top50_metadata_df = original_metadata_df[\n",
    "        original_metadata_df['species'].isin(species_mapping.keys())\n",
    "    ].copy()\n",
    "    \n",
    "    # Map the species names to their display names\n",
    "    top50_metadata_df['species'] = top50_metadata_df['species'].map(species_mapping)\n",
    "    \n",
    "    # Save filtered metadata\n",
    "    top50_metadata_df.to_csv(TOP50_METADATA, index=False)\n",
    "    print(f\"Saved metadata for {len(top50_metadata_df)} segments to {TOP50_METADATA}\")\n",
    "    \n",
    "    # Copy corresponding audio files\n",
    "    copied_files = 0\n",
    "    for _, row in top50_metadata_df.iterrows():\n",
    "        src_path = ORIGINAL_SEGMENTS_DIR / row['filename']\n",
    "        dst_path = TOP50_SEGMENTS_DIR / row['filename']\n",
    "        \n",
    "        if src_path.exists():\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            copied_files += 1\n",
    "        else:\n",
    "            print(f\"Warning: File not found - {src_path}\")\n",
    "    \n",
    "    print(f\"Copied {copied_files} audio files to {TOP50_SEGMENTS_DIR}\")\n",
    "    \n",
    "    # Verify counts\n",
    "    unique_species = top50_metadata_df['species'].nunique()\n",
    "    print(f\"\\nDataset contains {unique_species} species and {len(top50_metadata_df)} segments\")\n",
    "    print(\"Top 50 species distribution:\")\n",
    "    print(top50_metadata_df['species'].value_counts().head(10))\n",
    "    print(\"...\")  # Truncated for brevity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Creating dataset for top 50 performing bird species...\")\n",
    "    create_top50_dataset()\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import (SelectKBest, mutual_info_classif, \n",
    "                                     RFE, SelectFromModel)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed' / 'birdcall_segments_5s_TOP50'\n",
    "METADATA_PATH = DATA_DIR / 'processed' / 'birdcall_metadata_TOP50.csv'\n",
    "FEATURES_DIR = DATA_DIR / 'features'\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Configuration\n",
    "FEATURES_PATH = FEATURES_DIR / 'birdcall_features_TOP50.csv'\n",
    "OUTPUT_DIR = FEATURES_DIR / 'selected_feature_TOP50'\n",
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1  # Use all available cores\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_and_preprocess_features(features_path):\n",
    "    \"\"\"Load features and preprocess data\"\"\"\n",
    "    df = pd.read_csv(features_path)\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop(columns=['species', 'call_type', 'filename'])\n",
    "    y = df['species']\n",
    "    \n",
    "    # Encode species names to numerical labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    return X_scaled, y_encoded, df, le\n",
    "\n",
    "def comprehensive_feature_selection(X, y):\n",
    "    \"\"\"Multi-method feature selection pipeline\"\"\"\n",
    "    print(\"\\nüîç Running comprehensive feature selection...\")\n",
    "    \n",
    "    # 1. Mutual Information (Filter method)\n",
    "    print(\"  - Mutual Information selection...\")\n",
    "    mi_selector = SelectKBest(mutual_info_classif, k=20)\n",
    "    mi_selector.fit(X, y)\n",
    "    mi_features = X.columns[mi_selector.get_support()]\n",
    "    \n",
    "    # 2. Recursive Feature Elimination (Wrapper method)\n",
    "    print(\"  - Recursive Feature Elimination...\")\n",
    "    rfe_selector = RFE(\n",
    "        estimator=SVC(kernel=\"linear\", random_state=RANDOM_STATE),\n",
    "        n_features_to_select=20,\n",
    "        step=5\n",
    "    )\n",
    "    rfe_selector.fit(X, y)\n",
    "    rfe_features = X.columns[rfe_selector.get_support()]\n",
    "    \n",
    "    # 3. Random Forest Importance (Embedded method)\n",
    "    print(\"  - Random Forest Importance...\")\n",
    "    rf = RandomForestClassifier(n_estimators=500, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    rf.fit(X, y)\n",
    "    rf_selector = SelectFromModel(rf, prefit=True, threshold=\"1.25*mean\")\n",
    "    rf_features = X.columns[rf_selector.get_support()]\n",
    "    \n",
    "    # 4. XGBoost Importance (Embedded method)\n",
    "    print(\"  - XGBoost Importance...\")\n",
    "    xgb = XGBClassifier(n_estimators=500, random_state=RANDOM_STATE, n_jobs=N_JOBS)\n",
    "    xgb.fit(X, y)\n",
    "    xgb_selector = SelectFromModel(xgb, prefit=True, threshold=\"1.25*mean\")\n",
    "    xgb_features = X.columns[xgb_selector.get_support()]\n",
    "    \n",
    "    # Combine results\n",
    "    feature_scores = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'MI_score': mi_selector.scores_,\n",
    "        'RFE_rank': rfe_selector.ranking_,\n",
    "        'RF_importance': rf.feature_importances_,\n",
    "        'XGB_importance': xgb.feature_importances_\n",
    "    })\n",
    "    \n",
    "    # Calculate consensus score\n",
    "    feature_scores['consensus_score'] = (\n",
    "        feature_scores['MI_score'].rank() +\n",
    "        (X.shape[1] - feature_scores['RFE_rank']).rank() +\n",
    "        feature_scores['RF_importance'].rank() +\n",
    "        feature_scores['XGB_importance'].rank()\n",
    "    )\n",
    "    \n",
    "    # Get top 20 features by consensus\n",
    "    top_features = feature_scores.nlargest(20, 'consensus_score')['feature'].tolist()\n",
    "    \n",
    "    return top_features, feature_scores\n",
    "\n",
    "def visualize_feature_space(X, y, features, method='PCA'):\n",
    "    \"\"\"Dimensionality reduction visualization\"\"\"\n",
    "    print(f\"\\nüìä Visualizing feature space with {method}...\")\n",
    "    \n",
    "    # Select top features\n",
    "    X_top = X[features]\n",
    "    \n",
    "    if method == 'PCA':\n",
    "        reducer = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "        components = reducer.fit_transform(X_top)\n",
    "        x_label, y_label = 'PC1', 'PC2'\n",
    "    else:  # t-SNE\n",
    "        reducer = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=30)\n",
    "        components = reducer.fit_transform(X_top)\n",
    "        x_label, y_label = 't-SNE1', 't-SNE2'\n",
    "    \n",
    "    # Create interactive plot\n",
    "    fig = px.scatter(\n",
    "        x=components[:, 0], y=components[:, 1],\n",
    "        color=y, hover_name=y,\n",
    "        labels={'color': 'Species'},\n",
    "        title=f\"{method} Projection of Top Features\"\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=x_label,\n",
    "        yaxis_title=y_label,\n",
    "        legend_title_text='Species'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return components\n",
    "\n",
    "def plot_feature_importance(feature_scores, top_features):\n",
    "    \"\"\"Visualize feature importance metrics\"\"\"\n",
    "    print(\"\\nüìà Plotting feature importance...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    top_scores = feature_scores[feature_scores['feature'].isin(top_features)]\n",
    "    top_scores = top_scores.sort_values('consensus_score', ascending=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=(\n",
    "        \"Mutual Information Scores\", \n",
    "        \"Random Forest Importance\",\n",
    "        \"XGBoost Importance\",\n",
    "        \"Consensus Ranking\"\n",
    "    ))\n",
    "    \n",
    "    # Mutual Information\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_scores['feature'],\n",
    "            y=top_scores['MI_score'],\n",
    "            name=\"MI Score\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Random Forest\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_scores['feature'],\n",
    "            y=top_scores['RF_importance'],\n",
    "            name=\"RF Importance\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # XGBoost\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_scores['feature'],\n",
    "            y=top_scores['XGB_importance'],\n",
    "            name=\"XGB Importance\"\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Consensus\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_scores['feature'],\n",
    "            y=top_scores['consensus_score'],\n",
    "            name=\"Consensus\"\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=1200,\n",
    "        showlegend=False,\n",
    "        title_text=\"Feature Importance Metrics\"\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    fig.show()\n",
    "\n",
    "def plot_feature_clustering(X, y, features):\n",
    "    \"\"\"Hierarchical clustering of features\"\"\"\n",
    "    print(\"\\nüå≥ Plotting feature clustering...\")\n",
    "    \n",
    "    # Calculate correlations\n",
    "    corr = X[features].corr()\n",
    "    \n",
    "    # Calculate distance matrix\n",
    "    dist_matrix = 1 - np.abs(corr)\n",
    "    dist_matrix = np.nan_to_num(dist_matrix)\n",
    "    \n",
    "    # Perform hierarchical clustering\n",
    "    linkage_matrix = linkage(dist_matrix, 'ward')\n",
    "    \n",
    "    # Plot dendrogram\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    dendrogram(\n",
    "        linkage_matrix,\n",
    "        labels=features,\n",
    "        orientation='top',\n",
    "        leaf_rotation=90\n",
    "    )\n",
    "    plt.title('Hierarchical Clustering of Features')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_distributions(X, y, features):\n",
    "    \"\"\"Violin plots of top features\"\"\"\n",
    "    print(\"\\nüéª Plotting feature distributions...\")\n",
    "    \n",
    "    # Select top 4 features\n",
    "    top4 = features[:4]\n",
    "    df = X[top4].copy()\n",
    "    df['species'] = y\n",
    "    \n",
    "    # Melt for seaborn\n",
    "    df_melt = df.melt(id_vars='species', var_name='feature')\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.violinplot(\n",
    "        data=df_melt,\n",
    "        x='feature',\n",
    "        y='value',\n",
    "        hue='species',\n",
    "        split=True,\n",
    "        inner='quartile',\n",
    "        palette='Set3'\n",
    "    )\n",
    "    plt.title('Distribution of Top Features Across Species')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_selected_features(df, features, output_dir):\n",
    "    \"\"\"Save selected features and metadata\"\"\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save selected features\n",
    "    selected_df = df[['filename', 'species', 'call_type'] + features]\n",
    "    selected_df.to_csv(f\"{output_dir}/selected_features.csv\", index=False)\n",
    "    \n",
    "    # Save feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'rank': range(1, len(features)+1)\n",
    "    })\n",
    "    feature_importance.to_csv(f\"{output_dir}/feature_importance.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Saved selected features to {output_dir}\")\n",
    "def plot_grouped_dimensionality(X, y, features, method='PCA', n_groups=5, species_per_group=10):\n",
    "    \"\"\"Plot PCA/t-SNE in groups of 10 species for better visualization.\"\"\"\n",
    "    unique_species = sorted(y.unique())\n",
    "    \n",
    "    # Split into groups of 10 species\n",
    "    species_groups = np.array_split(unique_species, n_groups)\n",
    "    \n",
    "    for i, group in enumerate(species_groups):\n",
    "        print(f\"\\nüìä {method} - Group {i+1}: {', '.join(group)}\")\n",
    "        \n",
    "        # Filter data for current group\n",
    "        mask = y.isin(group)\n",
    "        X_group = X[mask][features]\n",
    "        y_group = y[mask]\n",
    "        \n",
    "        if method == 'PCA':\n",
    "            reducer = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "        else:  # t-SNE\n",
    "            reducer = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=min(30, len(X_group)-1))\n",
    "        \n",
    "        components = reducer.fit_transform(X_group)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(\n",
    "            x=components[:, 0], y=components[:, 1],\n",
    "            hue=y_group,\n",
    "            palette='tab20',\n",
    "            s=100,\n",
    "            alpha=0.8\n",
    "        )\n",
    "        plt.title(f\"{method} - Group {i+1} ({len(group)} species)\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"üî¨ Starting Scientific Feature Engineering Pipeline\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Load and preprocess data\n",
    "        X, y_encoded, df, label_encoder = load_and_preprocess_features(FEATURES_PATH)\n",
    "        \n",
    "        # 2. Feature selection\n",
    "        top_features, feature_scores = comprehensive_feature_selection(X, y_encoded)\n",
    "        print(f\"\\n‚úÖ Selected top 20 features:\")\n",
    "        print(\"\\n\".join(f\"- {f}\" for f in top_features))\n",
    "        \n",
    "        # 3. Visualizations\n",
    "        plot_feature_importance(feature_scores, top_features)\n",
    "        plot_feature_clustering(X, df['species'], top_features)\n",
    "        plot_feature_distributions(X, df['species'], top_features)\n",
    "        \n",
    "        # 4. Grouped Dimensionality Reduction (5 PCA & 5 t-SNE plots)\n",
    "        print(\"\\nüìä Generating Grouped Dimensionality Reduction Plots...\")\n",
    "        plot_grouped_dimensionality(X, df['species'], top_features, method='t-SNE')\n",
    "        \n",
    "        # 5. Save results\n",
    "        save_selected_features(df, top_features, OUTPUT_DIR)\n",
    "        \n",
    "        print(\"\\nüéâ Feature engineering completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Pipeline failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
